This article describes the various endpoints within the TimeXtender API and how to send requests using the TimeXtender Postman collection.To use the collection, download and install Postman, download the collection, open Postmanand import the collection into Postman. The API Keyneeds to be setup in order to use the TimeXtender API endpoints. Once entered, the apiKey variable isused for the entire collection, as the variable is referenced in therequest headers for the various calls. Alternatively, the variable above can be entered manually within the request headers for the individual calls. For example, the {{apiKey}} variable for the job status request can be replaced with the actual API key. The following variables are included in the Postman collection: As mentioned in the Prerequisites section above, ApiKey must be added in the variables section in Postman.For some of the endpoints, JobId and TriggerId variables also need to be added by modifying the current value in the Variables section. GET /public/jobs This endpoint retrieves a list of all jobs for yourorganization. Each job consists of the following values: POST /public/jobs/{job_id}/execute This endpoint will queue a job for execution by setting its status to "pending". The job will then be picked up by the application, at which point it will start the job execution along with execution logs.If successful, an object will be returned with the following properties: JobId(guid)- the Id of the job which has been queued to execute. Message(string)- a message explaining that the job has been started. TriggerId(guid)- a trigger id is unique to an execution and will be attached to the created logs once the job has been started. It can be used to filter logs. GET /public/jobs/{job_id}/status Thisendpoint can be used to check the current status of a job. The following status codes exist: A job will be "idle" until it has been executed. It will then go to status "pending". Once picked up by the application, it will change to status "running". When the execution finishes (or fails), the job will return to status "idle".The status endpoint will return an object with the following properties: GET /public/jobs/status This endpoint will return a list of statuses for all jobs in an organization. The status objects in the list will look identical to the one from the Get Job Status endpoint.The all jobs statuses endpoint will return an array of objects with the following properties: GET /public/jobs/{job_id}/logs This endpoint returns an array of job executions, as well as logs for a specific job.Ajob executionhas the following properties: Ajob execution loghas the following properties: GET /public/jobs/{job_id}/logs/{trigger_id} Thisendpoint returns a similar result as the Get Job Logs endpoint, except it will only return logs with a trigger Id matching the one given as a route parameter. In other words, this endpoint allows filtering of logs based on a trigger Id.   This is great and exactly what we have been waiting for! TheGet Job Logs Endpoint will be especially useful for us since we have our own monitoring app in Power BI using this info. Hi @Christian Hauggaard, I like to create a table in TimeXtender that containsthe last date and time a datasource in the ODX Server is successfully loaded. I'm looking for a API endpoint that can give me the last successful data transfer per datasourcein the ODX Server. The Job Logs endpoint give me some insights, but I cannot figure out which datasource/data transfer task the Job Log belongs to. @bas.hopstakenthe Job Logs Endpoint refers to the name of the transfer task in the message (although not the data source). So if you extract this data you should be able to find out which transfer task completed successfully at which time. As a workaround, if you name the transfer task so that it contains the data source name, then you should be able to tell which data source the transfer task belongs to. Please feel free to submit an idea here.  @Christian Hauggaard: I will rename my transfer tasks to include the data source name. But nevertheless it will be great if we can extract the status/execution logs from the ODX tasks and MDW/SSL instance Execution Packages ass well, using the API. Hi@Christian Hauggaard, I would like to set up a new Data Source in TimeXtender which extracts data from the TimeXtender API Endpoints. However my knowledge in the new version of TimeXtender is quite limited, especially when it comes to configuring REST API data sources in the portal. I have managed to extract the get job logs in postman in accordance with your guide. I would like to do extract the same info directly in TimeXtender. Could you provide me with guidance how thiscould be accomplished?  Best regards, Markus Great to hear that the API is live! This will be a welcome development for our V20 clients that have been hesitant about moving to V21 due to a lack of this type of feature.Now, when are endpoints coming for the Catalog? Another demand for our clients is to be able to surface the design and lineage information outside of TimeXtender so that it can be shared with their end user community. A set of endpoints to surface that information would be amazing! I have been working on creating some RSD files to use for this. To make them work you need to change the locations where I have added xxxx Once you have added either your own API key and if necessary an existing Job Id it will work. You only have to add the path to the location of the files in the Location field in the REST data source. Try them out, I have some different methods I use, some may work better for your setup. To apply any of the query slicers, you will need to create a managed query like this.  Hi team, Quick question; which aspect of jobs and executions in TimeXtender are called a trigger in this API? Kind regards, Andrew Hi @andrew.gebhard A Trigger Id is unique to an execution of a job and will be attached to the created logs once the job has been started. The primary purpose of aTrigger Id is to filter logs. Please note that only scheduled executions will generate a Trigger Id. Manual executions of a job will resultin the below blank Trigger Id. For example if a job is scheduled to run twice a day. Thentwo new Trigger Ids will appear in the job logs per day for that job. Please let me know if this answers your question? My development team tracks modifications in the description field of each object, using a #-sign to reference the specific DevOps work item driving the change. We extract these descriptions from the local project repository and augment them with information from our DevOps Work Items. I have documented this process in an article, which you can read here: https://www.linkedin.com/pulse/powerbi-timextender-devops-enhancing-deployment-insight-marco-noordam However, with the transition to a new cloud repository, this method is no longer viable. Perhaps TimeXtender could adjust to our workflow, providing a comprehensive changelog for each object that is directly linked to DevOps? ;-)  @mnoordaminnovative solution, thanks for sharing! Please feel free to submit a product idea here:https://support.timextender.com/ideas @Christian Hauggaardwill do, thx!  For those that are using TimeXtender with Qlik Cloud, we have a blog post about how to schedule TimeXtender jobs with Qlik Application Automation that you may find interesting:https://www.bitmetric.nl/blog/schedule-timextender-jobs-qlik-automation/ How long are jobs logs retained by the API? There doesn't seem to be any paging on the job logs endpoint. Won't this data set become quite bulky after a while? Would also be good to have date filters so we can use incremental loading. How long are jobs logs retained by the API? There doesn't seem to be any paging on the job logs endpoint. Won't this data set become quite bulky after a while? Would also be good to have date filters so we can use incremental loading.  @Christian Hauggaard Any input on this? Already have an account? Login No account yet? Create an account Enter your username or e-mail address. We'll send you an e-mail with instructions to reset your password. Sorry, we're still checking this file's contents to make sure it's safe to download. Please try again in a few minutes. Sorry, our virus scanner detected that this file isn't safe to download.